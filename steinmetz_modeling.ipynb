{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/PZVT7IFuvCqu895ZaB0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanQS/neuromatch_project/blob/main/steinmetz_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling of the Steinmetz dataset\n",
        "\n",
        "- uses [Neuromatch Load Steinmetz Decisions](https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/projects/neurons/load_steinmetz_decisions.ipynb#scrollTo=DJ-jzsE5eLxX) as a base"
      ],
      "metadata": {
        "id": "IDojqX3X1w30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K0fUDdS41qWU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from sklearn.decomposition import PCA\n",
        "import concurrent.futures\n",
        "from multiprocessing import Pool\n",
        "from typing import Dict, List, Any\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# !pip install -q ipython-autotime\n",
        "# %load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Data Downloading And Stacking\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "all_ds = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  all_ds = np.hstack((all_ds,\n",
        "                      np.load('steinmetz_part%d.npz'%j,\n",
        "                              allow_pickle=True)['dat']))"
      ],
      "metadata": {
        "id": "SNH_c8UKVK84",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Description\n",
        "\n",
        "(taken and modified from the Neuromatch Load Steinmetz Decisions notebook)\n",
        "\n",
        "## High-level\n",
        "\n",
        "`all_ds` contains 39 sessions from 10 mice, data from Steinmetz et al, 2019. Time bins for all measurements are 10ms, starting 500ms before stimulus onset. The mouse had to determine which side has the highest contrast. For each `curr_ds = all_ds[k]`, you have the fields below. For extra variables, check out the extra notebook and extra data files (lfp, waveforms and exact spike times, non-binned).\n",
        "\n",
        "## Fields Used\n",
        "\n",
        "* `curr_ds['spks']`: neurons by trials by time bins.    \n",
        "* `curr_ds['brain_area']`: brain area for each neuron recorded.\n",
        "* `curr_ds['response']`: which side the response was (`-1`, `0`, `1`). When the right-side stimulus had higher contrast, the correct choice was `-1`. `0` is a no go response.\n",
        "\n",
        "## Fields present (not all are used)\n",
        "\n",
        "* `curr_ds['mouse_name']`: mouse name\n",
        "* `curr_ds['date_exp']`: when a session was performed\n",
        "* `curr_ds['ccf']`: Allen Institute brain atlas coordinates for each neuron.\n",
        "* `curr_ds['ccf_axes']`: axes names for the Allen CCF.\n",
        "* `curr_ds['contrast_right']`: contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n",
        "* `curr_ds['contrast_left']`: contrast level for left stimulus.\n",
        "* `curr_ds['gocue']`: when the go cue sound was played.\n",
        "* `curr_ds['response_time']`: when the response was registered, which has to be after the go cue. The mouse can turn the wheel before the go cue (and nearly always does!), but the stimulus on the screen won't move before the go cue.  \n",
        "* `curr_ds['feedback_time']`: when feedback was provided.\n",
        "* `curr_ds['feedback_type']`: if the feedback was positive (`+1`, reward) or negative (`-1`, white noise burst).  \n",
        "* `curr_ds['wheel']`: turning speed of the wheel that the mice uses to make a response, sampled at `10ms`.\n",
        "* `curr_ds['pupil']`: pupil area  (noisy, because pupil is very small) + pupil horizontal and vertical position.\n",
        "* `curr_ds['face']`: average face motion energy from a video camera.\n",
        "* `curr_ds['licks']`: lick detections, 0 or 1.   \n",
        "* `curr_ds['trough_to_peak']`: measures the width of the action potential waveform for each neuron. Widths `<=10` samples are \"putative fast spiking neurons\".\n",
        "* `curr_ds['%X%_passive']`: same as above for `X` = {`spks`, `pupil`, `wheel`, `contrast_left`, `contrast_right`} but for  passive trials at the end of the recording when the mouse was no longer engaged and stopped making responses.\n",
        "* `curr_ds['prev_reward']`: time of the feedback (reward/white noise) on the previous trial in relation to the current stimulus time.\n",
        "* `curr_ds['reaction_time']`: ntrials by 2. First column: reaction time computed from the wheel movement as the first sample above `5` ticks/10ms bin. Second column: direction of the wheel movement (`0` = no move detected).  \n",
        "\n",
        "\n",
        "The original dataset is here: https://figshare.com/articles/dataset/Dataset_from_Steinmetz_et_al_2019/9598406"
      ],
      "metadata": {
        "id": "6R9YTk2nlj57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regions = [\"vis ctx\", \"thal\", \"hipp\", \"other ctx\", \"midbrain\", \"basal ganglia\", \"cortical subplate\", \"other\"]\n",
        "region_colors = ['blue', 'red', 'green', 'darkblue', 'violet', 'lightblue', 'orange', 'gray']\n",
        "brain_groups = [[\"VISa\", \"VISam\", \"VISl\", \"VISp\", \"VISpm\", \"VISrl\"],  # visual cortex\n",
        "                [\"CL\", \"LD\", \"LGd\", \"LH\", \"LP\", \"MD\", \"MG\", \"PO\", \"POL\", \"PT\", \"RT\", \"SPF\", \"TH\", \"VAL\", \"VPL\", \"VPM\"], # thalamus\n",
        "                [\"CA\", \"CA1\", \"CA2\", \"CA3\", \"DG\", \"SUB\", \"POST\"],  # hippocampal\n",
        "                [\"ACA\", \"AUD\", \"COA\", \"DP\", \"ILA\", \"MOp\", \"MOs\", \"OLF\", \"ORB\", \"ORBm\", \"PIR\", \"PL\", \"SSp\", \"SSs\", \"RSP\",\"TT\"],  # non-visual cortex\n",
        "                [\"APN\", \"IC\", \"MB\", \"MRN\", \"NB\", \"PAG\", \"RN\", \"SCs\", \"SCm\", \"SCig\", \"SCsg\", \"ZI\"],  # midbrain\n",
        "                [\"ACB\", \"CP\", \"GPe\", \"LS\", \"LSc\", \"LSr\", \"MS\", \"OT\", \"SNr\", \"SI\"],  # basal ganglia\n",
        "                [\"BLA\", \"BMA\", \"EP\", \"EPd\", \"MEA\"]  # cortical subplate\n",
        "                ]"
      ],
      "metadata": {
        "id": "R-TrPD1RaSdE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_IDX = 11\n",
        "curr_ds = all_ds[DATASET_IDX]\n",
        "\n",
        "dt = curr_ds[\"bin_size\"]\n",
        "NUM_NEURONS_RECORDED = curr_ds[\"spks\"].shape[0]\n",
        "NUM_TRIALS = curr_ds[\"spks\"].shape[1]\n",
        "NUM_BINNED_TIMES = curr_ds[\"spks\"].shape[2]\n",
        "\n",
        "if DATASET_IDX != 11:\n",
        "    raise Exception(\"Code is only meant for DATASET_IDX=11\")\n",
        "else:\n",
        "    NUM_REGIONS = 4\n",
        "    NUM_NEURONS_RECORDED = len(curr_ds[\"brain_area\"])  # The string idx version of\n",
        "\n",
        "brain_subregions = NUM_REGIONS * np.ones(NUM_NEURONS_RECORDED, )  # last one is \"other\"\n",
        "for j in range(NUM_REGIONS):\n",
        "  brain_subregions[\n",
        "      np.isin(curr_ds['brain_area'], brain_groups[j])\n",
        "      ] = j  # assign a number to each region\n"
      ],
      "metadata": {
        "id": "UKkzVgrtaUIK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the dataset\n",
        "\n",
        "1) Create the labels\n",
        "\n",
        "2) Create a dataset dictionary where the keys are brain areas (sub-regions) and the values are all the neuron readings that are in that area/sub-region\n",
        "\n",
        "3) Enable users to specify their config of how they want the data: do we consider region interactions, should we consider the start/middle/end of the spike train, etc."
      ],
      "metadata": {
        "id": "YWUD2SeXvb79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = curr_ds[\"response\"]  # RIGHT - NO_GO - LEFT (-1, 0, 1)\n",
        "y = LABELS"
      ],
      "metadata": {
        "id": "KdR8dZCikHnf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Logging for Sanity Checking\n",
        "def log_shapes(ds):\n",
        "    _ds = ds['spks']\n",
        "    print(f\"All spikes shape: {_ds.shape}\")\n",
        "    _ds_brain_region = _ds[brain_subregions == 0]\n",
        "    print(f\"\\t- Spike shape for sample brain region (0-th): {_ds_brain_region.shape}\")\n",
        "\n",
        "    _ds_0th_left_response = _ds_brain_region[:, y >= 0]\n",
        "    print(f\"\\t- Spike shape for sample brain region (0-th) left responses: {_ds_0th_left_response.shape}\")\n",
        "\n",
        "    averaged_over_left_response = _ds_0th_left_response.mean(axis=(0, 1))\n",
        "    print(f\"\\t- Averaged brain region (0-th) left responses: {averaged_over_left_response.shape}\")\n",
        "\n",
        "log_shapes(curr_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MJOM-3S5gfq",
        "outputId": "a745d49a-8f94-45a0-b87d-deab4538095e",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All spikes shape: (698, 340, 250)\n",
            "\t- Spike shape for sample brain region (0-th): (145, 340, 250)\n",
            "\t- Spike shape for sample brain region (0-th) left responses: (145, 199, 250)\n",
            "\t- Averaged brain region (0-th) left responses: (250,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Creating the Fine-Grained Data Dictionary (RUN ME!)\n",
        "def dataset_by_subregion(arr_of_subregions: List[str], ds: Dict[str, Any]) -> Dict[str, List[np.ndarray]]:\n",
        "    spike_partitioned = {}  # brain region to spike mapping\n",
        "    unique_subregions = set(arr_of_subregions)\n",
        "    for subregion in unique_subregions:\n",
        "        subregion_idxs = arr_of_subregions == subregion\n",
        "        subregion_data = ds[\"spks\"][subregion_idxs]\n",
        "\n",
        "\n",
        "        # from the \"Dataset Description\" section above\n",
        "        #       > which side the response was (-1, 0, 1)\n",
        "        spikes_for_right_response = subregion_data[:, y < 0]\n",
        "        spikes_for_left_response = subregion_data[:, y > 0]\n",
        "\n",
        "        # spikes_for_no_response = subregion_data[:, y == 0]\n",
        "\n",
        "        spike_partitioned[subregion] = [\n",
        "            spikes_for_left_response,\n",
        "            # spikes_for_no_response,\n",
        "            spikes_for_right_response\n",
        "        ]\n",
        "    return spike_partitioned\n",
        "\n",
        "subregion_data_dict = dataset_by_subregion(curr_ds[\"brain_area\"], curr_ds)\n",
        "\n",
        "print(\"Number of Neurons recorded in each subregion \")\n",
        "running_sum = 0\n",
        "for k, v in subregion_data_dict.items():\n",
        "    print(f\"\\t{k}\\t {v[0].shape[0]}\")\n",
        "    running_sum += v[0].shape[0]\n",
        "\n",
        "assert running_sum == curr_ds[\"spks\"].shape[0], \"Our totaled neurons across all subregions are not equal to the number of neurons measured\"\n",
        "print(running_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukGSq1aDibUS",
        "outputId": "76044723-b74a-46e2-e65b-fa88efc009e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neurons recorded in each subregion \n",
            "\tVISp\t 66\n",
            "\tVISam\t 79\n",
            "\tDG\t 65\n",
            "\tLGd\t 11\n",
            "\tCA1\t 50\n",
            "\tSUB\t 105\n",
            "\tLH\t 18\n",
            "\tPL\t 56\n",
            "\tACA\t 16\n",
            "\troot\t 100\n",
            "\tMD\t 126\n",
            "\tMOs\t 6\n",
            "698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Coarse-Grained Data Dictionary\n",
        "\n",
        "- we do this manually since we do not have too many subregions\n",
        "\n",
        "### All regions\n",
        "```python\n",
        "[\"VISa\", \"VISam\", \"VISl\", \"VISp\", \"VISpm\", \"VISrl\"],  # visual cortex\n",
        "[\"CL\", \"LD\", \"LGd\", \"LH\", \"LP\", \"MD\", \"MG\", \"PO\", \"POL\", \"PT\", \"RT\", \"SPF\", \"TH\", \"VAL\", \"VPL\", \"VPM\"], # thalamus\n",
        "[\"CA\", \"CA1\", \"CA2\", \"CA3\", \"DG\", \"SUB\", \"POST\"],  # hippocampal\n",
        "[\"ACA\", \"AUD\", \"COA\", \"DP\", \"ILA\", \"MOp\", \"MOs\", \"OLF\", \"ORB\", \"ORBm\", \"PIR\", \"PL\", \"SSp\", \"SSs\", \"RSP\",\"TT\"],  # non-visual cortex\n",
        "[\"APN\", \"IC\", \"MB\", \"MRN\", \"NB\", \"PAG\", \"RN\", \"SCs\", \"SCm\", \"SCig\", \"SCsg\", \"ZI\"],  # midbrain\n",
        "[\"ACB\", \"CP\", \"GPe\", \"LS\", \"LSc\", \"LSr\", \"MS\", \"OT\", \"SNr\", \"SI\"],  # basal ganglia\n",
        "[\"BLA\", \"BMA\", \"EP\", \"EPd\", \"MEA\"]  # cortical subplate\n",
        "```\n",
        "\n",
        "\n",
        "### Refined Regions\n",
        "\n",
        "- only the ones relevant to our dataset\n",
        "\n",
        "```python\n",
        "MD -> thalamus\n",
        "ACA -> non-visual-cortex\n",
        "SUB -> hippocampal\n",
        "CA1 -> hippocampal\n",
        "DG -> hippocampal\n",
        "LGd -> thalamus\n",
        "LH -> thalamus\n",
        "PL -> non-visual-cortex\n",
        "root ->\n",
        "VISp -> visual-cortex\n",
        "MOs -> non-visual-cortex\n",
        "VISam -> visual-cortex\n",
        "```"
      ],
      "metadata": {
        "id": "mNg0_VE7ot00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Creating the Coarse-Grained Data Dictionary\n",
        "def consolidate_fine_grained(subregion_dict):\n",
        "\n",
        "    mapping = {\n",
        "        \"thalamus\": [\"MD\", \"LGd\", \"LH\"],\n",
        "        \"non-visual-cortex\": [\"ACA\", \"PL\", \"MOs\"],\n",
        "        \"hippocampal\": [\"SUB\", \"CA1\", \"DG\"],\n",
        "        \"visual-cortex\": [\"VISp\", \"VISam\"]\n",
        "    }\n",
        "\n",
        "\n",
        "    coarse_region_data_dict: Dict[str, List[List[np.ndarray]]] = dict()\n",
        "\n",
        "    for coarse_region_name, subregion_name_arr in mapping.items():\n",
        "        print(\"*\" * 10)\n",
        "        print(coarse_region_name)\n",
        "        for subregion_name in subregion_name_arr:\n",
        "            print(f\"Subregion: {subregion_name}\")\n",
        "            if coarse_region_name not in coarse_region_data_dict:\n",
        "                print(f\"\\tInit: Left and Right: {subregion_dict[subregion_name][0].shape}, {subregion_dict[subregion_name][1].shape}\")\n",
        "                coarse_region_data_dict[coarse_region_name] = copy.deepcopy(subregion_dict[subregion_name])\n",
        "            else:\n",
        "                subregion_left, subregion_right = subregion_dict[subregion_name]\n",
        "\n",
        "                print(f\"\\tIncoming Shapes: Left and Right: {subregion_left.shape}, {subregion_right.shape}\")\n",
        "                # print(f\"Container: {coarse_region_data_dict[coarse_region_name][1]}\")\n",
        "                coarse_region_data_dict[coarse_region_name][0] = np.vstack(\n",
        "                    (coarse_region_data_dict[coarse_region_name][0],\n",
        "                    subregion_left)\n",
        "                )\n",
        "                coarse_region_data_dict[coarse_region_name][1] = np.vstack(\n",
        "                    (coarse_region_data_dict[coarse_region_name][1],\n",
        "                    subregion_right)\n",
        "                )\n",
        "            print(f\"\\tPost-stack shapes: {coarse_region_data_dict[coarse_region_name][0].shape} {coarse_region_data_dict[coarse_region_name][1].shape}\")\n",
        "    return coarse_region_data_dict\n",
        "\n",
        "coarse_region_data_dict = consolidate_fine_grained(subregion_data_dict)"
      ],
      "metadata": {
        "id": "AJ9Vo6TzoyhU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Constructing the Dataset (pre-processing)\n",
        "\n",
        "def populate_data(designed_matrix, is_left, X_container, y_container, min_num_spikes):\n",
        "    \"\"\"\n",
        "    designed_matrix is of shape (a, b, c)\n",
        "        a:= num_neurons in coarse_region\n",
        "        b:= num_trials  (in this case either the left or right response trials)\n",
        "        c:= spike_train\n",
        "    \"\"\"\n",
        "    OFFSET_FOR_ONE_HOT = 1\n",
        "    for trials_matrix in designed_matrix:\n",
        "        for spike_train in trials_matrix:\n",
        "            non_zero_length = sum(spike_train[len(coarse_region_data_dict):] > 0)\n",
        "            if non_zero_length > min_num_spikes + OFFSET_FOR_ONE_HOT:  #\n",
        "                X_container.append(spike_train)\n",
        "                y_container.append(1 if is_left else -1)\n",
        "    return X_container, y_container\n",
        "\n",
        "def encode_coarse_data(\n",
        "    coarse_data_dict: Dict[str, List[List[np.ndarray]]],\n",
        "    min_num_spikes\n",
        "):\n",
        "    unique_keys = dict()\n",
        "    one_hot_idx = 0\n",
        "\n",
        "    X_container = []\n",
        "    y_container = []\n",
        "    for coarse_region_name, coarse_region_data in coarse_data_dict.items():\n",
        "        print(\"*\" * 20)\n",
        "        print(coarse_region_name)\n",
        "        # Enumerate all of the arrays of the subregions and vertically stack them\n",
        "        left = coarse_region_data[0]   # The positive label (left) of our LGd, for example\n",
        "        right = coarse_region_data[1]  # The negative label (right) of our LH, for example\n",
        "        _l_shape = left.shape\n",
        "        _r_shape = right.shape\n",
        "\n",
        "        assert _l_shape[-1] == 250\n",
        "        assert _r_shape[-1] == 250\n",
        "\n",
        "\n",
        "        ##########################################\n",
        "        # Add 1-hot encoded data\n",
        "        #   For more information: https://en.wikipedia.org/wiki/One-hot\n",
        "\n",
        "        vec_one_hot = [0 for _ in range(len(coarse_region_data_dict.keys()))]\n",
        "        vec_one_hot[one_hot_idx] = 1\n",
        "        #[1, 0, 0, 0]\n",
        "        left_pad = np.tile(vec_one_hot, (_l_shape[0], _l_shape[1], 1))\n",
        "        right_pad = np.tile(vec_one_hot, (_r_shape[0], _r_shape[1], 1))\n",
        "        left_designed = np.concatenate((left_pad, left), axis=-1)\n",
        "        right_designed = np.concatenate((right_pad, right), axis=-1)\n",
        "\n",
        "        # print(f\"Shape B4 populating: {np.asarray(X_container).shape}, {np.asarray(y_container).shape}\")\n",
        "        pre_population_length = len(X_container)\n",
        "        X_container, y_container = populate_data(left_designed, True, X_container, y_container, min_num_spikes)\n",
        "        X_container, y_container = populate_data(right_designed, False, X_container, y_container, min_num_spikes)\n",
        "        post_population_length = len(X_container)\n",
        "        print(f\"\\tPre-population Length: {pre_population_length}\")\n",
        "        print(f\"\\tTotal Samples in {coarse_region_name}: {left_designed.shape[0] * left_designed.shape[1] + right_designed.shape[0] * right_designed.shape[1]}\")\n",
        "        print(f\"\\tSamples from {coarse_region_name} inserted post-min_num_spikes filtering: {post_population_length - pre_population_length}\")\n",
        "\n",
        "\n",
        "        # We are now in a new region, so we increment the index for the one-hot\n",
        "        one_hot_idx += 1\n",
        "\n",
        "    return np.asarray(X_container), np.asarray(y_container)"
      ],
      "metadata": {
        "id": "5B-hL3DCYtDP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Configuration\n",
        "\n",
        "Here we use the `DATASET_PARAMETERS` that was specified above"
      ],
      "metadata": {
        "id": "Wp7vLufeu4B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset_parameters, X_data, y_data):\n",
        "    \"\"\"\n",
        "    DATASET_PARAMETERS[\"window_choice\"] = WindowChoice.END\n",
        "    DATASET_PARAMETERS[\"window_size\"] = WINDOW_SIZE\n",
        "    DATASET_PARAMETERS[\"train-test-split\"] = TRAIN_TEST_SPLIT\n",
        "    \"\"\"\n",
        "\n",
        "    ##############################################\n",
        "    # First step is we extract the spike train window of interest based on whether we want the start, mid, or end\n",
        "    window_choice = dataset_parameters[\"window_choice\"]\n",
        "\n",
        "    if dataset_parameters[\"coarse\"]:\n",
        "        region_offset_for_onehot = len(coarse_region_data_dict)\n",
        "    else:\n",
        "        raise NotImplementedError(\"Not yet supported\")\n",
        "\n",
        "    if window_choice == WindowChoice.START:\n",
        "        start = region_offset_for_onehot\n",
        "        end = start + dataset_parameters[\"window_size\"] + region_offset_for_onehot\n",
        "    elif window_choice == WindowChoice.MID:\n",
        "        start = X_data.shape[-1] // 2\n",
        "        end = start + dataset_parameters[\"window_size\"]\n",
        "    else:\n",
        "        start = (X_data.shape[-1] - 1) - dataset_parameters[\"window_size\"]\n",
        "        end = (X_data.shape[-1] - 1)\n",
        "\n",
        "    idxs_to_use = list(range(region_offset_for_onehot)) + list(range(start, end))\n",
        "    new_Xs = []\n",
        "    for row in X_data:\n",
        "        new_Xs.append(row[idxs_to_use])\n",
        "    X_data = np.asarray(new_Xs)\n",
        "\n",
        "    ##############################################\n",
        "    # Optionally shuffle the dataset\n",
        "    if dataset_parameters[\"shuffle\"]:\n",
        "        X_data, y_data = shuffle(X_data, y_data)\n",
        "\n",
        "    if dataset_parameters[\"false_as_0\"]:\n",
        "        y_data = np.maximum(y_data, 0)\n",
        "\n",
        "    ##############################################\n",
        "    # Next step is to split into train-test\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size= dataset_parameters[\"train-test-split\"], random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "ifAvUl5Qu_v6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Do the modeling!\n",
        "\n",
        "Feel free to try different models and play to your hearts content :)\n",
        "\n",
        "**NOTE**\n",
        "\n",
        "You may want to try what happens as you increase the \"drop\" count parameter. What I've observed is that with a window of 100 elements,\n",
        "\n",
        "```\n",
        "mean \t4.393311\n",
        "std \t8.028090\n",
        "min \t0.000000\n",
        "25% \t0.000000\n",
        "50% \t1.000000\n",
        "75% \t5.000000\n",
        "max \t84.000000\n",
        "```\n",
        "\n",
        "which is insane, because it means that 75% of our data has just 5 elements in that 100-range.\n",
        "\n",
        "At a window size of 250, we have the following statistics:\n",
        "\n",
        "```\n",
        "count \t132038.000000\n",
        "mean \t10.849104\n",
        "std \t19.008744\n",
        "min \t0.000000\n",
        "25% \t0.000000\n",
        "50% \t2.000000\n",
        "75% \t13.000000\n",
        "max \t183.000000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Remember a few things:\n",
        "\n",
        "1) K-fold cross-validation might be useful\n",
        "\n",
        "2) accuracy is a good test-measure here because we are doing a classification task\n",
        "\n",
        "3) The shape of each row of the training data is 254. The first 4 are what is\n",
        "called a 1-hot encoding and basically encodes for which part of the brain we are looking at (there are 4 parts in our problem setup). The remaining 250 (or smaller, depending on what you set the window size and all that) are spike train data.\n",
        "\n",
        "4) Remember that regularization might be helpful if you are overfitting.\n",
        "\n",
        "5) Check out \"confusion matrix\" to help you understand where your model is making mistakes.\n",
        "\n",
        "Have fun!"
      ],
      "metadata": {
        "id": "RQCud45GxuLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Misc Setup (Run me!)\n",
        "\n",
        "import enum\n",
        "\n",
        "class WindowChoice(enum.Enum):\n",
        "    START = 0\n",
        "    MID = 1\n",
        "    END = 2"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5PF_vPOOBLWc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################\n",
        "# TODO: Set parameters as you see fit!\n",
        "###################################################\n",
        "\n",
        "WINDOW_SIZE = 249\n",
        "TRAIN_TEST_SPLIT = 0.8  # 80% is training, 20% test\n",
        "SHUFFLE_DATASET = True\n",
        "FALSE_AS_0 = True  # Convert the false case to 0 instead of -\n",
        "USE_COARSE_DATASET = True\n",
        "WINDOW_CHOICE = WindowChoice.END\n",
        "MIN_NUM_SPIKES = 50  # The minimum number of spikes in the entire array for us to use it in the dataset\n",
        "\n",
        "assert 0 < TRAIN_TEST_SPLIT <= 1.0\n",
        "\n",
        "\n",
        "DATASET_PARAMETERS = dict()\n",
        "\n",
        "DATASET_PARAMETERS[\"window_choice\"] = WINDOW_CHOICE\n",
        "DATASET_PARAMETERS[\"window_size\"] = WINDOW_SIZE\n",
        "DATASET_PARAMETERS[\"train-test-split\"] = TRAIN_TEST_SPLIT\n",
        "DATASET_PARAMETERS[\"shuffle\"] = SHUFFLE_DATASET\n",
        "DATASET_PARAMETERS[\"false_as_0\"] = FALSE_AS_0\n",
        "DATASET_PARAMETERS[\"coarse\"] = USE_COARSE_DATASET\n",
        "DATASET_PARAMETERS[\"min_num_spikes\"] = MIN_NUM_SPIKES\n"
      ],
      "metadata": {
        "id": "ituLJu-nAn1w"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DATASET_PARAMETERS[\"coarse\"]:\n",
        "    Xs, ys = encode_coarse_data(\n",
        "        coarse_region_data_dict,\n",
        "        DATASET_PARAMETERS[\"min_num_spikes\"]\n",
        "    )\n",
        "else:\n",
        "    raise NotImplementedError(\"Fine-Grained dataset not supported yet\")\n",
        "X_train, X_test, y_train, y_test = create_dataset(DATASET_PARAMETERS, Xs, ys)\n",
        "\n",
        "summed_ax_1 = np.sum(X_train, axis=1) - 1  # Have to subtract 1 since our 1-hot encoding makes us have an \"inflated\" 1\n",
        "\n",
        "pd.DataFrame(summed_ax_1).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "8buMl6cuzhRI",
        "outputId": "0b7deed5-7cc2-4d60-8622-757a931ce52f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "thalamus\n",
            "\tPre-population Length: 0\n",
            "\tTotal Samples in thalamus: 42780\n",
            "\tSamples from thalamus inserted post-min_num_spikes filtering: 4176\n",
            "********************\n",
            "non-visual-cortex\n",
            "\tPre-population Length: 4176\n",
            "\tTotal Samples in non-visual-cortex: 21528\n",
            "\tSamples from non-visual-cortex inserted post-min_num_spikes filtering: 13\n",
            "********************\n",
            "hippocampal\n",
            "\tPre-population Length: 4189\n",
            "\tTotal Samples in hippocampal: 60720\n",
            "\tSamples from hippocampal inserted post-min_num_spikes filtering: 1878\n",
            "********************\n",
            "visual-cortex\n",
            "\tPre-population Length: 6067\n",
            "\tTotal Samples in visual-cortex: 40020\n",
            "\tSamples from visual-cortex inserted post-min_num_spikes filtering: 494\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count  5248.000000\n",
              "mean     79.035823\n",
              "std      26.378363\n",
              "min      51.000000\n",
              "25%      60.000000\n",
              "50%      69.000000\n",
              "75%      90.000000\n",
              "max     183.000000"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9725cc25-8956-4516-a892-299fc713e72b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5248.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>79.035823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>26.378363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>51.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>69.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>183.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9725cc25-8956-4516-a892-299fc713e72b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-061f5630-f259-48be-8873-0cfdd1eba72d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-061f5630-f259-48be-8873-0cfdd1eba72d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-061f5630-f259-48be-8873-0cfdd1eba72d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9725cc25-8956-4516-a892-299fc713e72b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9725cc25-8956-4516-a892-299fc713e72b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}